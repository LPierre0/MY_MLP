# Multi-Layer Perceptron (MLP) from Scratch

## Objective

This project aims to enhance my skills in C++, GPU programming, and deep learning by implementing a Multi-Layer Perceptron (MLP) from scratch. The goal is to gain a deep understanding of how MLPs function and to develop an extendable architecture that could later be integrated into a Convolutional Neural Network (CNN).

## Approach

MLP Implementation: Develop a fully customizable MLP in C++ with GPU acceleration.

Dataset: Use the MNIST dataset for evaluation, as it is widely known and provides a solid benchmark.

Comparison: Train an equivalent MLP using TensorFlow in Python to compare performance and accuracy.

## Future Enhancements

Extend the MLP for CNN integration.

Optimize GPU performance for larger datasets.

Explore different activation functions and training techniques.

## Why This Project?

Deepen understanding of neural networks at a fundamental level.

Improve C++ and GPU programming proficiency.

Build a foundation for more complex deep learning architectures.
